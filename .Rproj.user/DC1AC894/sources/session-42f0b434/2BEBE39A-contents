---
title: "Improve Working with Incomplete Data"
title-block-banner: "#EBA900"
title-block-banner-color: "white"
author: 
  - name: 
      given: Sanghoon
      family: Park
      literal: Sanghoon Park
    orcid: 0000-0001-5365-0013
    email: pherephobia@gmail.com
    url: www.sanghoon-park.com
    affiliations:
      - name: Political Science, University of South Carolina
        address: #305 Gambrell Hall, 817 Henderson Street
        city: Columbia
        state: SC
        postal-code: 29208-4114
date: 2023-02-06
date-format: short
format:
  html:
    toc: true
    toc-depth: 4
    html-math-method: katex
    theme:
      light: [cosmo, styles.scss]
      dark: [cosmo, styles-dark.scss]
    highlight-style: "atom-one"
    code-link: true
    css: styles.css
    toc-location: right
    df-print: paged
editor: visual
number-sections: false
bibliography: references.bib
---

## Attention!

::: {.callout-caution appearance="minimal"}
Here, I assume:

1.  that you already know how to import data into R.
2.  that you already know how to use `{tidyverse}` workflow using pipes (`%>%`) from `{magrittr}` or native pipes (`|>`). I will use native pipes.

The goal of today's class is to identify:

-   what do we need to merge different data sets?

-   what are possible/potential problems when we merge data sets?
:::

## Load Packages

```{r}
#| label: load-packages
#| include: false
library(tidyverse)
library(mosaic)
library(showtext)

# font 등록
font_add_google(name = "Public Sans", family = "public-sans")
font_add_google(name = "Lato", family = "Lato")
font_add_google(name = "Montserrat", family = "Montserrat")

# chunk 설정
knitr::opts_chunk$set(warning = F, error = F, message = F)

# showtext 기능 켜기
showtext_auto(TRUE)
theme_set(theme_minimal(base_family = "Montserrat") + 
    tomtom::theme_538() +
    theme(
      axis.title = element_text(family = "Montserrat"),
      axis.text = element_text(family = "Montserrat"),
      panel.grid.major.y = element_blank(),
      panel.grid.minor = element_blank(),
      plot.background = element_rect(fill = "white", color = "white")
  ))
```

```{r}
if (!require(tidyverse)) install.packages("tidyverse")
library(tidyverse)
```

## Example Data in Use

We will use two different example data sets from `V-Dem` and `World Development Indicators`. The two example data sets are available for download here: [example1](https://github.com/pherephobia/3_NazarbayevDS/blob/90f4c802cd9ad18d1fb33c43332a434dc0d71656/examples/example1.csv) and [example2](https://github.com/pherephobia/3_NazarbayevDS/blob/90f4c802cd9ad18d1fb33c43332a434dc0d71656/examples/example2.csv). Because the example data is in csv format, you must use the appropriate function to import the example data sets into R. I put them in a folder called `examples`. We will also use other data sets that are built into R.

```{r}
example1 <- read_csv("examples/example1.csv")
example2 <- read_csv("examples/example2.csv")
```

Let's look at the data set structures:

```{r}
glimpse(example1)
```

`example1` is drawn from the [V-Dem](https://v-dem.net/) data set. `glimpse()` function is tidyverse version of the base R function, `str()`, which shows the structure of a data frame. `example1` has 3,922 observations (rows) and 9 variables (columns). It has four id variables (`country_name`, `country_text_id`, `country_id`, `COWcode`), as well as one year variable (`year`). `v2x_polyarchy` is the "Electoral Democracy Index (EDI)," which measures procedural democracy based on the suggestions of @dahl1971a . `e_polity2` is an alternative measure of democracy from POLITY project, while `e_fh_cl` and `e_fh_pr` are drawn from the "Freedom House Index," which represents civil liberties and political rights.

```{r}
glimpse(example2)

```

`example2` is from the [World Development Indicators](https://databank.worldbank.org/source/world-development-indicators), World Bank. When we look at the data, we see that there are 4,220 observations (rows) and 11 variables (columns). `example2` includes five country-id variables (`ccode`, `cname`, `ccodealp`, `ccodecow`, `ccodewb`) as well as year-related variables (`year`, `cname_year`, `ccodealp_year`). It also has two additional variables: GDP per capita, PPP (constant 2017 US dollars), which is gross domestic product converted to US dollars using purchasing power parity rates and the trade openness that is the sum of exports and imports of goods and services measured as a share of gross domestic product.

Because I filtered both example data sets from 2001, `example1` is between 2001 and 2022 and `example2` is between 2001 and 2020.

## Incomplete Data, what does it mean?

What does the term "incomplete data" mean? Because survey data is designed to answer specific questions, the information provided by the data is usually sufficient to answer our research questions. Also, as the units are different, it is difficult to merge survey data with other data sets unless we keep tracing and surveying the same respondents.

When we use non-survey observational data, we may run into an incomplete data problem, which means that a single data set is insufficient to answer our questions. To solve this problem, we must combine multiple incomplete data sets to make them complete.

The process of combining multiple data sets into a single data set is known as merging. Adding inflation factors to panel data to adjust income to today's rates is one example, as is adding county-level statistics to individual-level data. We'll look at two kinds of merges: adding columns from one data set to another and adding rows (also known as appending).

### Adding rows

The actual act of merging two data sets usually involves only one or two lines of code. Most of the work when merging happens before this, in preparing data frames for merging and in deciding which rows we want in the output.

Let’s create two data frames from `example1`: `example1_1` and `example1_2`.

```{r}
example1_1 <- example1 |> dplyr::select(1:6) |> 
  dplyr::filter(country_name %in% c("Mexico", "South Korea"))
example1_2 <- example1 |> dplyr::select(1:5, 7:9) |> 
  dplyr::filter(country_name %in% c("United States of America", "South Korea"))
```

To merge two data frames, we need keys, identifiers that we can use to match one set of information to another. A common example of a key in the social sciences is a person ID, which can be used to link information across multiple data sets. However, our `example1` is not an individual level data. Thus, keys will be `country` and `year` identifiers: `country_name`, `country_text_id`, `country_id`, `COWcode`, `year`.

```{r}
head(example1_1)
```

```{r}
glimpse(example1_1)
```

```{r}
head(example1_2)
```

```{r}
glimpse(example1_2)
```

What we want to accomplish with our merge is to collect them all into a single data set. The question we have to answer first is, which rows do we want to appear in our merged data set? Currently, both data sets share variables `country_name`, `country_text_id`, `country_id`, `COWcode`, and `year`. Beyond that, one has data for Mexico, and the other for the United States of America.

Now, you know that the two different data sets share the keys and have only one different values for country. When the data sets share the keys, it is easy to combine them into one data frame: use `bind_rows()`.

```{r}
bind_rows(example1_1, example1_2)
```

```{r}
bind_rows(example1_1, example1_2) |> glimpse()
```

When you supply a column name with the `.id` argument, a new \# column is created to link each row to its original data frame `bind_rows(list(example1_1, example1_2), .id = "id")`

```{r}
bind_rows(list(example1_1, example1_2), .id = "id")
```

```{r}
bind_rows("group 1" = example1_1, "group 2" = example1_2, .id = "groups")

```

Columns don't need to match when row-binding.

```{r}
bind_rows(tibble(x = 1:3), tibble(y = 1:4))
```

Row sizes must be compatible when column-binding, otherwise you will see error messages.

```{r}
#| error: true
try(bind_cols(tibble(x = 1:3), tibble(y = 1:2)))
```

Also, `bind_rows()` is picky about matching column types, and it will not automatically coerce columns to be of the same type. Instead, it will return an error. We can fix this by manually coercing column types to character before merging.

```{r}
survey1 <-
  data.frame(Q1 = c(1, 1),
             Q2 = c(3, 1),
             Q2a = c("Sometimes", NA),
             Q3 = c(6, 7),
             Q3a = c("Never", "Always"))
glimpse(survey1)
survey2 <-
  data.frame(Q1 = c(2, 4, 4),
             Q2 = c(1, 5, 3),
             Q2a = c(NA, NA, 2),
             Q3 = c(4, 2, 5),
             Q3a = c(NA, NA, NA))
glimpse(survey2)
```

When we use `bind_rows()` for `survey1` and `survey2`, the error message tells us that column `Q2a` is character in one data frame and numeric in the other.

```{r}
#| error: true
bind_rows(survey1, survey2)
```

This happened here because `c()` automatically assigned a type based on the values it observed. When we read in datasets, `read.csv()` and related functions will also use the values to determine the type. Differences in responses between two datasets, especially for open-response questions, can lead to different types assigned to the two datasets’ columns.

To fix this, simply coerce the problem column in one dataset to match the type of that column in the other dataset. Then, use `bind_rows()`.

```{r}
survey2b <- 
  survey2 |>
  mutate(Q2a = as.character(Q2a))

surveys <- bind_rows(survey1, survey2b)

surveys
```

`bind_rows()` changes the number of rows (observations) of the combined data set.

::: {.callout-tip appearance="simple"}
## When is `bind_rows()` useful?

`bind_rows()` can be useful if you have multiple data sources and want to combine them into one. Suppose you download multiple data sets for a country but from different years from the same website. If they have the same keys, you can use `bind_rows()` to combine them and create a new variable, `year` with the `.id` option in `bind_rows()`.
:::

### Adding columns

While `bind_rows()` is about the number of observations, `bind_cols()` is about the number of variables. When you have a set of shared keys and two different data sets with different variables, you can combine them into one.

```{r}
names(example1_1)
names(example1_2)
```

`example1_1` contains the variable, `v2x_polyarchy` whereas `example1_2` has `e_polity2`, `e_fh_cl`, `e_fh_pr`. As you may be aware, the two separated data sets share country and year identifiers. Thus, you want to create a combined data set with country and year identifiers with `v2x_polyarchy`, `e_polity2`, `e_fh_cl`, `e_fh_pr`.

```{r}
bind_cols(example1_1, example1_2)
```

However, it seems something weird since it has two times of variables more than the original data sets. What happens? `bind_cols()` function binds any number of data frames by column, making a wider result. However, it requires that row sizes must be compatible when column-binding. Therefore, where possible prefer using a [join](https://dplyr.tidyverse.org/reference/mutate-joins.html) to combine multiple data frames. `bind_cols()` binds the rows in order in which they appear so it is easy to create meaningless results without realising it. We will see the `*_join()` functions in the next section.

```{r}
glimpse(bind_cols(example1_1, example1_2))
```

::: {.callout-tip appearance="simple"}
## When is `bind_cols()` useful?

`bind_cols()` can be useful when you combine two different data frames, which you already know what they are:

```{r}
# Load diamonds data set
data(diamonds)

# Fit a simple regression model
fit <- lm(price ~ carat, data = diamonds)

# Make the fitted results as data frame
if (!require(broom)) install.packages("broom")
broom::tidy(fit)

# {broom} package provides the function, tidy(), which returns the fitted
# results as a tidy data frame.
# However, it does not provide you confidence intervals.
# You can get confidence intervals using the function confint_tidy().
broom::confint_tidy(fit)

# Now you know that the two data frames can be combined:
bind_cols(
  broom::tidy(fit),
  broom::confint_tidy(fit)
)
```
:::

## Relational Data

> This subsection is borrowed from `Joins` section of @wickham2023 (Hereafter, [R4DS](https://r4ds.hadley.nz/)). Also, see @17mergi and @peng .

It’s rare that a data analysis involves only a single table of data. Typically you have many tables of data, and you must combine them to answer the questions that you’re interested in. Collectively, multiple tables of data are called **relational data** because it is the relations, not just the individual data sets, that are important.

Relations are always defined between a pair of tables. All other relations are built up from this simple idea: the relations of three or more tables are always a property of the relations between each pair. Sometimes both elements of a pair can be the same table! This is needed if, for example, you have a table of people, and each person has a reference to their parents.

To work with relational data you need verbs that work with pairs of tables. There are three families of verbs designed to work with relational data:

-   **Mutating joins**, which add new variables to one data frame from matching observations in another.

-   **Filtering joins**, which filter observations from one data frame based on whether or not they match an observation in the other table.

-   **Set operations**, which treat observations as if they were set elements.

The `dplyr` package provides a set of functions for joining two data frames into a single data frame based on a set of key columns. There are several functions in the `*_join` family. These functions all merge together two data frames; they differ in how they handle observations that exist in one but not both data frames. Here are the four functions from this family that you will likely use the most often:

| **Function** | **What it includes in merged data frame**                                                                 |
|---------------|---------------------------------------------------------|
| `left_join`  | Includes all observations in the left data frame, whether or not there is a match in the right data frame |
| `right_join` | Includes all observations in the right data frame, whether or not there is a match in the left data frame |
| `inner_join` | Includes only observations that are in both data frames                                                   |
| `full_join`  | Includes all observations from both data frames                                                           |

A common task in data analysis is to bring different data sets together, so that we can combine columns from two (or more) tables together.

This can be achieved using the *join* family of functions in `dplyr`. There are different types of *joins*, which can be represented by a series of Venn diagrams:

![](images/07-dplyr_joins.svg){fig-align="center"}

### Mutating joins

```{r}
head(example1); head(example2)
```

The `by` option is used to tell the *join* function which column(s) are used to “match” the rows of the two tables.

#### Inner join

![](images/inner_join.png)

### 

We can see that the output has fewer rows than both of these tables, which makes sense given we’re only keeping the “intersection” between the two.

#### Left join

![](images/left_join.png)

Now suppose we want to create a table that combines the information about different democracy measurements with country-year units. We can use the `left_join()` function to merge the `example1` and `example2` tables.

First, when you use `left_join()`, you have to determine which data frame should be a baseline.

#### Right join

![](images/right_join.png)

#### Full join

![](images/full_join.png)

### Filtering joins

#### Semi join

#### Anti join

### Join problems

### Set operations

## Make Dyads using Existing Data

### Directed dyads

### Non-directed dyads

## Complete Combination

### Complete

## Expand

## Expand/Complete with `group_by`

## Expand with nesting

## Crossing

## References {.unnumbered}
